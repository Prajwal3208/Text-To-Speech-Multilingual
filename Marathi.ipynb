{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiXE3wpp5eWRqMosZLwIbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajwal3208/Text-To-Speech-Multilingual/blob/main/Marathi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q gTTS pydub gradio transformers nltk langdetect\n",
        "# !apt install -y ffmpeg"
      ],
      "metadata": {
        "id": "wQ--Q94zN73S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ukzb9C0NQyyk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gm3HM80KQ0B3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('punkt_tab')  # ‚úÖ Force download punkt_tab if needed (rare bug)\n",
        "\n"
      ],
      "metadata": {
        "id": "q4uvdTTIP3zR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gtts import gTTS\n",
        "# from pydub import AudioSegment\n",
        "# from transformers import pipeline\n",
        "# import gradio as gr\n",
        "# import tempfile\n",
        "# import io\n",
        "# from nltk.tokenize import sent_tokenize\n",
        "# from langdetect import detect\n",
        "# import os"
      ],
      "metadata": {
        "id": "q5VTYyXbN_nZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")"
      ],
      "metadata": {
        "id": "HBCLDgxOOGEp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def emotion_to_audio_effect(audio, emotion):\n",
        "#     emotion = emotion.lower()\n",
        "#     if \"joy\" in emotion:\n",
        "#         return audio.speedup(1.2).apply_gain(+3)\n",
        "#     elif \"sad\" in emotion:\n",
        "#         return audio.speedup(0.9).apply_gain(-3)\n",
        "#     elif \"anger\" in emotion:\n",
        "#         return audio.speedup(1.3).apply_gain(+5)\n",
        "#     elif \"fear\" in emotion:\n",
        "#         return audio.speedup(0.95).apply_gain(-2)\n",
        "#     elif \"surprise\" in emotion:\n",
        "#         return audio.speedup(1.1).apply_gain(+2)\n",
        "#     else:\n",
        "#         return audio\n"
      ],
      "metadata": {
        "id": "WxCDaa5SOMKb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def detect_emotion(text):\n",
        "#     try:\n",
        "#         result = emotion_classifier(text)[0]\n",
        "#         return result['label']\n",
        "#     except:\n",
        "#         return \"neutral\""
      ],
      "metadata": {
        "id": "IlJX4wuiOPFj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def expressive_tts(text):\n",
        "#     try:\n",
        "#         sentences = sent_tokenize(text)\n",
        "#         final_audio = AudioSegment.silent(duration=500)\n",
        "\n",
        "#         for sent in sentences:\n",
        "#             emotion = detect_emotion(sent)\n",
        "#             print(f\"üîπ Sentence: {sent} | Emotion: {emotion}\")\n",
        "\n",
        "#             try:\n",
        "#                 lang = detect(sent)\n",
        "#                 if lang not in ['en', 'hi', 'mr']:\n",
        "#                     lang = 'en'\n",
        "#             except:\n",
        "#                 lang = 'en'\n",
        "\n",
        "#             try:\n",
        "#                 tts = gTTS(text=sent, lang=lang)\n",
        "#                 buf = io.BytesIO()\n",
        "#                 tts.write_to_fp(buf)\n",
        "#                 buf.seek(0)\n",
        "#                 audio = AudioSegment.from_file(buf, format=\"mp3\")\n",
        "#                 expressive_audio = emotion_to_audio_effect(audio, emotion)\n",
        "#                 final_audio += expressive_audio + AudioSegment.silent(duration=300)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"‚ùå TTS error: {e}\")\n",
        "\n",
        "#         with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_file:\n",
        "#             if len(final_audio) < 1000:\n",
        "#                 print(\"‚ö†Ô∏è Final audio is empty or very short.\")\n",
        "#                 beep = AudioSegment.silent(100).overlay(AudioSegment.sine(440).fade_out(300))\n",
        "#                 beep.export(tmp_file.name, format=\"mp3\")\n",
        "#             else:\n",
        "#                 final_audio.export(tmp_file.name, format=\"mp3\")\n",
        "\n",
        "#             print(f\"‚úÖ Audio file generated: {tmp_file.name}\")\n",
        "#             print(\"üîç File exists?\", os.path.exists(tmp_file.name), tmp_file.name)\n",
        "#             return tmp_file.name\n",
        "\n",
        "#     except Exception as err:\n",
        "#         print(f\"‚ùå General error: {err}\")\n",
        "#         return None\n"
      ],
      "metadata": {
        "id": "J6cGu7SbOS-q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gr.Interface(\n",
        "#     fn=expressive_tts,\n",
        "#     inputs=gr.Textbox(lines=4, label=\"Enter Multilingual Sentence (Marathi / Hindi / English)\"),\n",
        "#     outputs=gr.Audio(type=\"filepath\", label=\"Generated Expressive Speech\"),\n",
        "#     title=\"üéôÔ∏è Multilingual TTS with Emotion\",\n",
        "#     description=\"Type a sentence in Marathi, Hindi, or English. The AI will detect sentence emotions and speak accordingly.\"\n",
        "# ).launch(debug=True)"
      ],
      "metadata": {
        "id": "JwUqMYWjOVy7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YscpZ266Rt9Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gTTS pydub gradio transformers nltk langdetect soundfile torch\n",
        "!apt install -y ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZlS1NvJRnZH",
        "outputId": "0a24fc57-fc1b-44d5-dd87-436a04b587b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.6/981.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # ‚úÖ Force download punkt_tab if needed (rare bug)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTfOmVzKb3PB",
        "outputId": "d54d5816-c487-4c8e-8371-596917240ba5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment, effects\n",
        "from pydub.generators import Sine  # Added for tone generation\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import io\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from langdetect import detect, DetectorFactory\n",
        "import os\n",
        "import soundfile as sf\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "import warnings\n"
      ],
      "metadata": {
        "id": "LLVj4s-yZC4a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "pdWo6ULnSALg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DetectorFactory.seed = 0"
      ],
      "metadata": {
        "id": "Ljm-1CBwZYeo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize emotion classifier with device check\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "emotion_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJg-BLlZbsc",
        "outputId": "0c153ddc-d600-4a04-8038-04a91441f9b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOICE_PROFILES = {\n",
        "    'english': {\n",
        "        'female': {'tld': 'com', 'pitch': 1.2, 'speed': 1.0, 'voice_type': 'co.uk', 'max_chars': 3000},\n",
        "        'male': {'tld': 'com', 'pitch': 0.9, 'speed': 1.1, 'voice_type': 'us', 'max_chars': 3000},\n",
        "        'child': {'tld': 'com', 'pitch': 1.4, 'speed': 1.3, 'voice_type': 'co.uk', 'max_chars': 2000}\n",
        "    },\n",
        "    'hindi': {\n",
        "        'female': {'tld': 'co.in', 'pitch': 1.15, 'speed': 0.95, 'voice_type': 'ind', 'max_chars': 2500},\n",
        "        'male': {'tld': 'co.in', 'pitch': 0.95, 'speed': 1.0, 'voice_type': 'ind', 'max_chars': 2500},\n",
        "        'child': {'tld': 'co.in', 'pitch': 1.3, 'speed': 1.2, 'voice_type': 'ind', 'max_chars': 1500}\n",
        "    },\n",
        "    'marathi': {\n",
        "        'female': {'tld': 'co.in', 'pitch': 1.1, 'speed': 1.0, 'voice_type': 'ind', 'max_chars': 2500},\n",
        "        'male': {'tld': 'co.in', 'pitch': 0.92, 'speed': 1.05, 'voice_type': 'ind', 'max_chars': 2500},\n",
        "        'child': {'tld': 'co.in', 'pitch': 1.25, 'speed': 1.15, 'voice_type': 'ind', 'max_chars': 1500}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "hJEoY68RaVON"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_error_audio():\n",
        "    \"\"\"Create an error notification sound\"\"\"\n",
        "    # Generate two beeps\n",
        "    beep1 = Sine(440).to_audio_segment(duration=300).fade_out(50)\n",
        "    beep2 = Sine(330).to_audio_segment(duration=300).fade_out(50)\n",
        "    return AudioSegment.silent(200) + beep1 + AudioSegment.silent(200) + beep2\n",
        "\n",
        "def apply_emotion_effects(audio, emotion, intensity=1.0):\n",
        "    \"\"\"Apply emotional effects to audio with better handling\"\"\"\n",
        "    if len(audio) == 0:\n",
        "        return audio\n",
        "\n",
        "    emotion = emotion.lower()\n",
        "    try:\n",
        "        base_speed = 1.0\n",
        "        base_pitch = 1.0\n",
        "        base_volume = 0\n",
        "\n",
        "        emotion_profiles = {\n",
        "            'joy': {'speed': 1.2, 'pitch': 1.15, 'volume': 2},\n",
        "            'sadness': {'speed': 0.85, 'pitch': 0.9, 'volume': -3},\n",
        "            'anger': {'speed': 1.3, 'pitch': 1.1, 'volume': 4},\n",
        "            'fear': {'speed': 0.9, 'pitch': 1.05, 'volume': -2},\n",
        "            'surprise': {'speed': 1.1, 'pitch': 1.25, 'volume': 3},\n",
        "            'neutral': {'speed': 1.0, 'pitch': 1.0, 'volume': 0}\n",
        "        }\n",
        "\n",
        "        profile = emotion_profiles.get(emotion, emotion_profiles['neutral'])\n",
        "\n",
        "        # Apply effects with intensity\n",
        "        speed = min(2.0, max(0.5, base_speed + (profile['speed'] - base_speed) * intensity))\n",
        "        pitch = min(2.0, max(0.5, base_pitch + (profile['pitch'] - base_pitch) * intensity))\n",
        "        volume = min(10, max(-10, base_volume + profile['volume'] * intensity))\n",
        "\n",
        "        # Speed change\n",
        "        if speed != 1.0:\n",
        "            audio = effects.speedup(audio, playback_speed=speed)\n",
        "\n",
        "        # Pitch change\n",
        "        if pitch != 1.0:\n",
        "            samples = np.array(audio.get_array_of_samples())\n",
        "            if audio.channels == 2:\n",
        "                samples = samples.reshape((-1, 2))\n",
        "\n",
        "            new_sample_rate = int(audio.frame_rate * pitch)\n",
        "            audio = audio._spawn(samples, overrides={'frame_rate': new_sample_rate})\n",
        "            audio = audio.set_frame_rate(44100)\n",
        "\n",
        "        # Volume change\n",
        "        if volume != 0:\n",
        "            audio = audio + volume\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Emotion effect error: {e}\")\n",
        "        return audio\n",
        "\n",
        "def detect_language(text):\n",
        "    \"\"\"Improved language detection with fallback\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            return 'en'\n",
        "\n",
        "        lang = detect(text[:500])  # Only check first 500 characters\n",
        "        if lang in ['en', 'hi', 'mr']:\n",
        "            return lang\n",
        "        if lang in ['bn', 'pa', 'gu', 'ta', 'te', 'kn', 'ml']:\n",
        "            return 'hi'\n",
        "        return 'en'\n",
        "    except:\n",
        "        return 'en'\n",
        "\n",
        "def chunk_text(text, max_length=2000):\n",
        "    \"\"\"Split text into manageable chunks preserving sentences\"\"\"\n",
        "    if not text.strip():\n",
        "        return []\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 < max_length:\n",
        "            current_chunk += \" \" + sentence if current_chunk else sentence\n",
        "        else:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = sentence\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def generate_tts(text, language, voice_gender='female'):\n",
        "    \"\"\"Generate TTS audio with better error handling\"\"\"\n",
        "    if not text.strip():\n",
        "        return AudioSegment.silent(duration=100)\n",
        "\n",
        "    voice_profile = VOICE_PROFILES[language][voice_gender]\n",
        "    lang_code = 'en' if language == 'english' else ('hi' if language == 'hindi' else 'mr')\n",
        "\n",
        "    try:\n",
        "        # Split into chunks if too long\n",
        "        if len(text) > voice_profile['max_chars']:\n",
        "            chunks = chunk_text(text, voice_profile['max_chars'])\n",
        "            audio_segments = []\n",
        "\n",
        "            for chunk in chunks:\n",
        "                try:\n",
        "                    tts = gTTS(\n",
        "                        text=chunk,\n",
        "                        lang=lang_code,\n",
        "                        tld=voice_profile['tld'],\n",
        "                        slow=False\n",
        "                    )\n",
        "\n",
        "                    buf = io.BytesIO()\n",
        "                    tts.write_to_fp(buf)\n",
        "                    buf.seek(0)\n",
        "                    segment = AudioSegment.from_file(buf, format=\"mp3\")\n",
        "\n",
        "                    # Apply voice characteristics\n",
        "                    if voice_profile['speed'] != 1.0:\n",
        "                        segment = effects.speedup(segment, playback_speed=voice_profile['speed'])\n",
        "\n",
        "                    if voice_profile['pitch'] != 1.0:\n",
        "                        new_sample_rate = int(segment.frame_rate * voice_profile['pitch'])\n",
        "                        segment = segment._spawn(segment.raw_data, overrides={'frame_rate': new_sample_rate})\n",
        "\n",
        "                    segment = segment.set_frame_rate(44100)\n",
        "                    audio_segments.append(segment)\n",
        "                    time.sleep(0.3)  # Avoid rate limiting\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Chunk processing error: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not audio_segments:\n",
        "                raise ValueError(\"No audio segments generated\")\n",
        "\n",
        "            combined = AudioSegment.silent(duration=200)\n",
        "            for segment in audio_segments:\n",
        "                combined += segment + AudioSegment.silent(duration=200)\n",
        "\n",
        "            return combined\n",
        "        else:\n",
        "            # Single chunk processing\n",
        "            tts = gTTS(\n",
        "                text=text,\n",
        "                lang=lang_code,\n",
        "                tld=voice_profile['tld'],\n",
        "                slow=False\n",
        "            )\n",
        "\n",
        "            buf = io.BytesIO()\n",
        "            tts.write_to_fp(buf)\n",
        "            buf.seek(0)\n",
        "            audio = AudioSegment.from_file(buf, format=\"mp3\")\n",
        "\n",
        "            # Apply voice characteristics\n",
        "            if voice_profile['speed'] != 1.0:\n",
        "                audio = effects.speedup(audio, playback_speed=voice_profile['speed'])\n",
        "\n",
        "            if voice_profile['pitch'] != 1.0:\n",
        "                new_sample_rate = int(audio.frame_rate * voice_profile['pitch'])\n",
        "                audio = audio._spawn(audio.raw_data, overrides={'frame_rate': new_sample_rate})\n",
        "\n",
        "            audio = audio.set_frame_rate(44100)\n",
        "            return audio\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TTS generation error: {e}\")\n",
        "        return AudioSegment.silent(duration=100)\n",
        "\n",
        "def process_sentence(sentence_data):\n",
        "    \"\"\"Process a single sentence with better error handling\"\"\"\n",
        "    sent, language, voice_gender, emotion_intensity = sentence_data\n",
        "\n",
        "    if not sent.strip():\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Detect emotion (limit input length)\n",
        "        emotion_result = emotion_classifier(sent[:512])[0]\n",
        "        emotion = emotion_result['label']\n",
        "        confidence = min(1.0, max(0.1, emotion_result['score']))\n",
        "\n",
        "        # Generate base audio\n",
        "        audio = generate_tts(sent, language, voice_gender)\n",
        "        if len(audio) < 50:  # Skip if audio is too short\n",
        "            return None\n",
        "\n",
        "        # Apply emotion\n",
        "        effective_intensity = min(1.5, max(0.5, emotion_intensity * confidence))\n",
        "        expressive_audio = apply_emotion_effects(audio, emotion, effective_intensity)\n",
        "\n",
        "        return expressive_audio if expressive_audio else audio\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Sentence processing error: {e}\")\n",
        "        return None\n",
        "\n",
        "def expressive_tts(text, voice_gender='female', emotion_intensity=1.0, progress=gr.Progress()):\n",
        "    \"\"\"Main function with complete error handling\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            raise ValueError(\"Empty input text\")\n",
        "\n",
        "        # Detect primary language\n",
        "        lang_code = detect_language(text[:1000])\n",
        "        language = 'english' if lang_code == 'en' else ('hindi' if lang_code == 'hi' else 'marathi')\n",
        "\n",
        "        # Split into sentences\n",
        "        sentences = [s for s in sent_tokenize(text) if s.strip()]\n",
        "        if not sentences:\n",
        "            raise ValueError(\"No valid sentences found in text\")\n",
        "\n",
        "        print(f\"Processing {len(sentences)} sentences in {language} ({voice_gender} voice)\")\n",
        "\n",
        "        # Process in parallel with progress tracking\n",
        "        final_audio = AudioSegment.silent(duration=200)\n",
        "        batch_size = 4  # Conservative batch size for Colab\n",
        "        completed = 0\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=2) as executor:  # Reduced workers for stability\n",
        "            for i in range(0, len(sentences), batch_size):\n",
        "                batch = sentences[i:i + batch_size]\n",
        "                batch_data = [(sent, language, voice_gender, emotion_intensity) for sent in batch]\n",
        "\n",
        "                # Process batch\n",
        "                batch_results = []\n",
        "                for result in executor.map(process_sentence, batch_data):\n",
        "                    if result and len(result) > 50:  # Only add valid audio segments\n",
        "                        batch_results.append(result)\n",
        "\n",
        "                # Combine results\n",
        "                for result in batch_results:\n",
        "                    final_audio += result + AudioSegment.silent(duration=200)\n",
        "\n",
        "                # Update progress\n",
        "                completed += len(batch)\n",
        "                progress(completed / len(sentences), desc=\"Generating speech\")\n",
        "                time.sleep(0.5)  # Increased delay for stability\n",
        "\n",
        "        # Verify final audio\n",
        "        if len(final_audio) < 500:  # If too short, generate fallback\n",
        "            print(\"Warning: Generated audio too short, using fallback\")\n",
        "            fallback_text = text[:500] if len(text) > 50 else text\n",
        "            final_audio = generate_tts(fallback_text, language, voice_gender)\n",
        "            if len(final_audio) < 500:\n",
        "                final_audio = create_error_audio()\n",
        "\n",
        "        # Export final audio\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
        "            final_audio.export(tmp_file.name, format=\"wav\", bitrate=\"192k\")\n",
        "            print(f\"Successfully generated audio: {tmp_file.name} ({len(final_audio)/1000:.1f}s)\")\n",
        "            return tmp_file.name\n",
        "\n",
        "    except Exception as err:\n",
        "        print(f\"Fatal error in TTS: {err}\")\n",
        "        # Create error notification audio\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
        "            error_audio = create_error_audio()\n",
        "            error_audio.export(tmp_file.name, format=\"wav\")\n",
        "            return tmp_file.name\n"
      ],
      "metadata": {
        "id": "bHpGMSPGSyE0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "with gr.Blocks(title=\"üéôÔ∏è Working Multilingual TTS\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üéôÔ∏è Multilingual Text-to-Speech\n",
        "    ## With Emotion and Multiple Voices\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(\n",
        "            label=\"Enter text in English, Hindi, or Marathi\",\n",
        "            placeholder=\"Type or paste your text here...\",\n",
        "            lines=5,\n",
        "            max_lines=20\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            voice_gender = gr.Radio(\n",
        "                choices=[\"female\", \"male\", \"child\"],\n",
        "                value=\"female\",\n",
        "                label=\"Voice Type\"\n",
        "            )\n",
        "            emotion_intensity = gr.Slider(\n",
        "                minimum=0.5,\n",
        "                maximum=1.5,\n",
        "                value=1.0,\n",
        "                step=0.1,\n",
        "                label=\"Emotion Intensity\"\n",
        "            )\n",
        "            btn = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(\n",
        "                label=\"Generated Speech\",\n",
        "                type=\"filepath\",\n",
        "                interactive=False\n",
        "            )\n",
        "            status = gr.Textbox(\n",
        "                label=\"Status\",\n",
        "                value=\"Ready to generate speech...\",\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # Example texts\n",
        "    examples = [\n",
        "        [\"Hello world! This is a test of the text-to-speech system.\", \"female\", 1.0],\n",
        "        [\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ! ‡§Ø‡§π ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§π‡•à‡•§\", \"male\", 1.2],\n",
        "        [\"‡§π‡•Ö‡§≤‡•ã ‡§µ‡§∞‡•ç‡§≤‡•ç‡§°! ‡§π‡•á ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§‡•Ç‡§® ‡§è‡§ï ‡§ö‡§æ‡§ö‡§£‡•Ä ‡§Ü‡§π‡•á.\", \"child\", 0.8]\n",
        "    ]\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=[text_input, voice_gender, emotion_intensity],\n",
        "        label=\"Try these examples\"\n",
        "    )\n",
        "\n",
        "    def update_status(text, voice, emotion):\n",
        "        if not text.strip():\n",
        "            return \"Enter some text to generate speech\"\n",
        "        return f\"Generating {voice} voice with emotion intensity {emotion}...\"\n",
        "\n",
        "    text_input.change(\n",
        "        update_status,\n",
        "        inputs=[text_input, voice_gender, emotion_intensity],\n",
        "        outputs=status\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=expressive_tts,\n",
        "        inputs=[text_input, voice_gender, emotion_intensity],\n",
        "        outputs=[audio_output],\n",
        "        api_name=\"generate\"\n",
        "    ).then(\n",
        "        lambda: \"Speech generated successfully!\",\n",
        "        outputs=status\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "WZuHad3pbA1B",
        "outputId": "0778aa7b-67d8-4f7e-937a-542354d6e77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8369a66d02fa7a1913.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8369a66d02fa7a1913.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 sentences in english (female voice)\n",
            "Successfully generated audio: /tmp/tmpxbmja0a5.wav (1.2s)\n",
            "Processing 2 sentences in english (female voice)\n",
            "Successfully generated audio: /tmp/tmpr19s86ud.wav (4.4s)\n",
            "Processing 2 sentences in hindi (male voice)\n",
            "Successfully generated audio: /tmp/tmplms9lk8x.wav (5.0s)\n",
            "Processing 2 sentences in marathi (child voice)\n",
            "Successfully generated audio: /tmp/tmp5my4yn9c.wav (3.5s)\n",
            "Processing 2 sentences in marathi (male voice)\n",
            "Successfully generated audio: /tmp/tmpif81de84.wav (4.9s)\n",
            "Processing 2 sentences in marathi (female voice)\n",
            "Successfully generated audio: /tmp/tmpcjmm4dzw.wav (4.3s)\n",
            "Processing 12 sentences in marathi (male voice)\n",
            "Successfully generated audio: /tmp/tmplxn44fds.wav (99.1s)\n",
            "Processing 12 sentences in marathi (male voice)\n",
            "Successfully generated audio: /tmp/tmpzwxtjq8g.wav (99.1s)\n"
          ]
        }
      ]
    }
  ]
}